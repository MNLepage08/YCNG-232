{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Combine a rule-based and a machine-learning chatbot (like those of the example code), using rules and training data of your choice (you may retain the example setup if you wish) to implement a bot that answers clear-cut situations based on rules and defaults to the responses from a fitted neural network when no rule matches. Interact with it and discuss the strengths and the weaknesses of your bot. Please include code snippets and an example dialogue in your response.**"
      ],
      "metadata": {
        "id": "YLUinYhnEoq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.techwithtim.net/tutorials/ai-chatbot/part-1/"
      ],
      "metadata": {
        "id": "ZVm5RUWQG5om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKMhlDr9IFxB",
        "outputId": "a11ac42f-ac56-45bc-c5cc-fbe45e6d3c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 27.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=497bbe19048bf58dc1aac7d9bccb9573f0d37e11ee23ee869615703571bf53bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_RW0-qAG4y1",
        "outputId": "c1e34760-e69a-493e-a72f-b1a8ec76dcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy\n",
        "import tflearn\n",
        "import tensorflow\n",
        "import random\n",
        "\n",
        "# Load the json file\n",
        "\n",
        "import json\n",
        "with open('intents.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data with the json file\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADRBSOP1Ijsz",
        "outputId": "6c3e95fd-5e51-4aa1-9f1f-9ff792c34315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
              "   'responses': ['Hello, thanks for visiting',\n",
              "    'Good to see you again',\n",
              "    'Hi there, how can I help?'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
              "   'responses': ['See you later, thanks for visiting',\n",
              "    'Have a nice day',\n",
              "    'Bye! Come back again soon.']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
              "  {'tag': 'hours',\n",
              "   'patterns': ['What hours are you open?',\n",
              "    'What are your hours?',\n",
              "    'When are you open?'],\n",
              "   'responses': [\"We're open every day 9am-9pm\",\n",
              "    'Our hours are 9am-9pm every day']},\n",
              "  {'tag': 'payments',\n",
              "   'patterns': ['Do you take credit cards?',\n",
              "    'Do you accept Mastercard?',\n",
              "    'Are you cash only?'],\n",
              "   'responses': ['We accept VISA, Mastercard and AMEX',\n",
              "    'We accept most major credit cards']},\n",
              "  {'tag': 'opentoday',\n",
              "   'patterns': ['Are you open today?',\n",
              "    'When do you open today?',\n",
              "    'What are your hours today?'],\n",
              "   'responses': [\"We're open every day from 9am-9pm\",\n",
              "    'Our hours are 9am-9pm every day']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the data\n",
        "\n",
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "        \n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])"
      ],
      "metadata": {
        "id": "iXJal5sVIwhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Stemming to reduce the vocabulary of our model and attempt to find the more general meaning behind sentences.\n",
        "\n",
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "labels = sorted(labels)"
      ],
      "metadata": {
        "id": "533Tv894JHX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words\n",
        "# We need some way to represent our sentences with numbers and this is where a bag of words comes in.\n",
        "\n",
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)"
      ],
      "metadata": {
        "id": "QNDjp0iSJISv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our training data and output to numpy arrays\n",
        "\n",
        "training = numpy.array(training)\n",
        "output = numpy.array(output)"
      ],
      "metadata": {
        "id": "YC8b5ZnhJMn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Develop a model\n",
        "# The goal of our network will be to look at a bag of words and give a class that they belong too (one of our tags from the JSON file).\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y510laJiJRH7",
        "outputId": "6783ba9a-6405-4e14-cda9-b076744f0376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & saving the model\n",
        "\n",
        "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save(\"model.tflearn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXbHDKoXJ_z4",
        "outputId": "8ab756cf-d605-4dec-c785-821ad747707f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 2999  | total loss: \u001b[1m\u001b[32m0.00234\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 1000 | loss: 0.00234 - acc: 1.0000 -- iter: 16/20\n",
            "Training Step: 3000  | total loss: \u001b[1m\u001b[32m0.00236\u001b[0m\u001b[0m | time: 0.006s\n",
            "| Adam | epoch: 1000 | loss: 0.00236 - acc: 1.0000 -- iter: 20/20\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions:\n",
        "# – Get some input from the user\n",
        "# – Convert it to a bag of words\n",
        "# – Get a prediction from the model\n",
        "# – Find the most probable class\n",
        "# – Pick a response from that class\n",
        "\n",
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return numpy.array(bag)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        results_index = numpy.argmax(results)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))"
      ],
      "metadata": {
        "id": "sq6VcihJKWp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the chatbot\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X41jwrrKabt",
        "outputId": "15edefb9-0826-4b32-ef81-ef561041aeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: Hello\n",
            "Good to see you again\n",
            "You: Are you open Sunday?\n",
            "Our hours are 9am-9pm every day\n",
            "You: Can I pay with credit card?\n",
            "We accept VISA, Mastercard and AMEX\n",
            "You: Do you have chicken to sell?\n",
            "We accept most major credit cards\n",
            "You: ok thanks!\n",
            "My pleasure\n",
            "You: ciao\n",
            "We accept VISA, Mastercard and AMEX\n",
            "You: Bye\n",
            "Bye! Come back again soon.\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "J’ai appliqué un chatbot très similaire au cours selon le tutoriel ci-dessus. Importation d’un fichier json pour définir les questions / réponses du chatbot. Extraction du fichier. Les mots sont stemming pour réduire le vocabulaire pour mon modèle. Utilisation de bag of word pour représenter mes phrases en nombre dans mon modèle. Développement d’un modèle à l’aide de tensorflow. Pour faire les prédictions, il va prendre les phrases de l’utilisateur, les convertir en bag of words pour faire une prédiction selon mon modèle. Il trouvera la réponse la plus probable en envoyant la classe avec la probabilité la plus grande en guise de réponse.\n",
        "\n",
        "Les réponses selon ma structure définie dans mon fichier json fonctionne bien. Même si une phrase n’est pas identique à ma structure comme par exemple ‘Are you open Sunday?’, le modèle cherchera la meilleure réponse à donner qui est cohérent ‘Our hours are 9am-9pm every day’. Les phrases qui ne sont pas dans ma structure donne des réponses incohérente ‘Do you have chiken to sell? We accept most major credit cards’ ou utilisation d’une autre langue ‘ciao: We accept VISA, MasterCard and AMEX’."
      ],
      "metadata": {
        "id": "vNEIcZB6QP18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Does it sound like a good idea to continue training a chatbot based on the reactions that its responses elicit from the users in a live environment? What would you gain by doing this? What could go wrong? In what context could it make sense to do this?**"
      ],
      "metadata": {
        "id": "FdHYl-aCFmAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://phys.org/news/2021-07-customers-react-chatbots.html\n",
        "\n",
        "Selon cette référence, si les problèmes questionnés par l’utilisateur sont importants ou critiques, la réaction est négative du client lorsqu’il apprend que c’est un chatbot. Ceci affaiblie la confiance du client. Par contre, si le problème n’est pas résolu dans les questions, l’utilisateur a une réaction positive lorsqu’il sait que c’est un chatbot. L’utilisateur comprend plus facilement la cause de l’erreur et il plus indulgent è l’erreur d’une technologie qu’un humain.\n",
        "\n",
        "https://marutitech.com/benefits-chatbot/\n",
        "\n",
        "Les bénéfices d’un chatbot pour une compagnie:\n",
        "\n",
        "•\tRéduction des coûts : Permet aux entreprises de gérer une quantité importante de demandes clients dans des délais courts. Investissement d’un chatbot inférieur au modèle traditionnel de service à la clientèle.\n",
        "\n",
        "•\tOffrir aux clients du site web une assistance contextuelle à valeur ajoutées : Expérience personnalisée aux clients.\n",
        "\n",
        "•\tUne meilleure analyse des données clients : L’entreprise peut analyser les performances du bot en résultats commerciaux / ventes générées, informations détaillées sur la façon dont les gens s’engagent avec l’entreprise et leur demande. \n",
        "\n",
        "•\tAmélioration de l’engagement des clients et des ventes : La structure flexible des chatbots les rend faciles à les intégrer à d’autres systèmes, ce qui augmente l’engagement. Expérience rapide et sans tracas laisse le client heureux et satisfait.\n",
        "\n",
        "•\tGagner du temps : En résolvant les questions de base. Seules les requêtes complexes nécessitant une intervention humaine sont dirigées vers une équipe d’assistance.\n",
        "\n",
        "Application dans de multiple cas et industries :\n",
        "\n",
        "•\tMarketing, vente, service à la clientèle, service d’assistance IT.\n",
        "\n",
        "•\tService de la santé, banque et finance, éducation, ressource humaine, commerce de détail, tourisme.\n",
        "\n",
        "Il faut cependant faire attention aux problématiques d’étiques comme par exemple la sécurité des utilisateurs, biais textuels, vie privée des gens, générer des stéréotypes ou être nuisibles. Voir dans la question 3 pour plus de développement sur ces points.\n",
        "\n",
        "En somme, le chatbot me semble favorable.\n"
      ],
      "metadata": {
        "id": "ve3RefTK1Kpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How about training a chatbot in a completely non-supervised manner (meaning that no labeled data is ever used)? Does this sound feasible? What could cause difficulties with such an approach?**"
      ],
      "metadata": {
        "id": "DE2iFINpfm-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.searchunify.com/blog/the-rise-of-the-unsupervised-learning-based-chatbot-models/\n",
        "\n",
        "\n",
        "Les 2 premières générations de chatbots sont basées sur des modèles d’apprentissages automatique supervisés.\n",
        "\n",
        "•\tRéponses dénuées de sens pour des questions non définis.\n",
        "\n",
        "•\tÉtiquetage intensif des données pour la formation du modèle.\n",
        "\n",
        "\n",
        "Les modèles non supervisés reconnaissent des modèles et extraient l’intention des données recherchées par eux-mêmes. Ils offrent des suggestions d’intention aux administrateurs en données. Informations en temps réel qui fournissent des données sur des paramètres tels que l’interaction des utilisateurs, les intentions, etc. Ces chatbots s’auto-apprennent et s’améliore au fur et à mesure qu’ils reçoivent de nouvelles données. Réduit le temps de formation, l’administration et la maintenance nécessaire tout en améliorant la qualité des interactions avec le client.\n",
        "\n",
        "\n",
        "https://chatbotsmagazine.com/unsupervised-deep-learning-for-vertical-conversational-chatbots-c66f21b1e0f\n",
        "https://arxiv.org/pdf/1506.05869v3.pdf\n",
        "\n",
        "\n",
        "Une approche simple consiste à utiliser un cadre d’apprentissage profond non supervisé de type réseau neuronal récurrent séquence à séquence (seq2seq RNN). C’est un type de système (Vinyals-Le) questions/réponses issu de la traduction automatique. Le contexte est limité à la question en cours. Dans un contexte conversationnel étendu basé sur le dialogue, le contexte doit être maintenu à travers de multiples séquences de questions/réponses (exigence clé pour les systèmes de dialogue).\n",
        "\n",
        "•\tChatbots verticaux : domaine fermé axés sur des applications verticales particulières (plus simple). \n",
        "\n",
        "•\tChatbots horizontaux : domaine ouvert comme Siri, Google assistant ou Alexa.\n",
        "\n",
        "\n",
        "Les chatbots verticaux sont des systèmes axés sur les objectifs, ou le but de la conversation est d’obtenir des informations pour exécuter une action. La classification des intentions est moins problématique puisque le domaine vertical fournit un contexte pour la conversation. \n",
        "\n",
        "\n",
        "L’apprentissage non supervisé implique que le modèle peut être entraîné directement à partir des données historiques des transcriptions, sans qu’il soit nécessaire de recourir à un étiquetage humain. Si l’objectif est de construire un système de Q/A, nous pouvons traiter les conversations comme des paires de Q/A d’entrée, ou chaque phrase de la conversation est à la fois une réponse à la phrase précédente et une question à la phrase suivante. La taille et le contenu du vocabulaire sont un paramètre clé du modèle. Plus le vocabulaire est restreint, moins le temps de formation est long. Un petit nombre de vocabulaire entraîne un plus grand nombre d’entité unknow (données importantes pour la conversation mais qui ne peuvent pas figurer dans le vocabulaire). La gestion de ces inconnus est l’un des défis de la construction d’un chatbot vertical avec un vocabulaire spécifique. Les autres paramètres importants sont le nombre de layers, le type et le nombre de cellules utilisé pour chaque layers et le nombre autorisé pour chaque phrase.\n",
        "\n",
        "L’avantage de ce modèle est la simplicité avec peu de besoin de règles dépendantes du domaine. Les inconvénients sont l’adaptation à la tâche de construction des chatbots, la difficulté à maintenir le contexte dans les longues conversations et à tenir un dialogue cohérent. \n",
        "\n",
        "\n",
        "https://web.stanford.edu/~jurafsky/slp3/24.pdf\n",
        "\n",
        "\n",
        "L’éthique dans la conception de chatbot :\n",
        "\n",
        "•\tLa sécurité des utilisateurs : ex : conseils médicaux, situation d’urgence, etc. des conseils erronés peuvent être dangereux.\n",
        "\n",
        "•\tUn système peut attaquer verbalement et générer des stéréotypes abusifs ou nuisibles. Exemple Tay bot (https://en.wikipedia.org/wiki/Tay_(bot))\n",
        "\n",
        "•\tLa vie privée : L’omniprésence des chatbots à domicile signifie qu’ils peuvent souvent entendre des informations privées. Besoin d’anonymiser les informations d’identification personnelle.\n",
        "\n",
        "•\tSoulèvement d’importantes question d’égalité des sexes et biais textuels.\n"
      ],
      "metadata": {
        "id": "3xaWlF7B25W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.\tFind some chatbots (at least three) in the customer service options of the websites or social media of some companies or organizations that interest you. Test them out for a few minutes and write a brief review of each, speculating on how you imagine them to be implemented and if you can think of ways to improve them.**"
      ],
      "metadata": {
        "id": "cfVNiWppMIbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.adecco.fr/candidats/aloha/\n",
        "\n",
        "Aloha pour la recherche d’emploi : Facilite la recherche d’emploi et un bon moyen pour Adecco de sourcer plus facilement des nouveaux profils. Sans doute un chatbot ruled-based.\n",
        "\n",
        "Test: Elle ne comprend pas la recherche intelligence artificielle, science de données. Cependant, elle me propose 8 offres pour analyste de données. Je peux postuler ou accéder directement à l’annonce mais ils sont tous en France et certain ne me semble pas associé à ma recherche exactement (fonctions administratives, gestion comptabilité.) En tapant : gestion des données, Montréal. 5 nouvelles offres. J’accède à l’une d’entre elle (assistant contrôleur de gestion!), désolé cette offre d’emploi n’existe plus. Les deux autres essaient même chose. Je tente Montréal, cette fois un menu m’apparait avec affiner/modifier. Menu interactif : secteur / type de contrat / mots clés / Localissation. Menu déroulant avec faible éventail d’emploi (possiblement que la compagnie adecco se spécialise dans ce type d’emploi). Je tente conseiller. Suggestion d’offre d’emploi dans le paramédical en général. Désolé, cette offre d’emploi n’existe plus… Offres similaire (Villefranche De Lauragais, Haute-Garonne). Je ne sais pas si c’est seulement pour la France sachant que Adecco est établie à Montréal également.\n",
        "\n",
        "Bref, je trouve que le bot est un bel effort, il offre des fonctionnalités de recherches qui me semble pertinentes. Cependant je trouve qu’il manque de précision dans ce qu’ils offrent versus mes mots clés tapé ou sélectionné selon mon menu. Pour tous mes tests pour voir l’affiche du poste : désolé, cette offre n’existe plus. Au bout de 5 minutes je me suis tanné et je pense que je serais plus productive à faire ma recherche manuellement sur leur site.\n",
        "\n",
        "https://www.eviebot.com/en/\n",
        "\n",
        "Evie bot : Elle apprend des gens (non-supervisé). Avatar féminin qui réagit à mes questions en changeant son expression faciale. Déjà un avertissement au début : n’est pas fait pour les enfants. Elle apprend et imite. Contenu social qui vise à passer le test de Turing. Peut-être grossier ou inapproprié.\n",
        "\n",
        "Test : Je peux soit écrire ou dicter une phrase. Plusieurs langues, je choisie le français. Elle me répond en anglais. Si je lui dis que je parle en français elle change sa langue ce qui est bien. Quelque discussion avec le bot est je reçois des choses bizarres comme : tu fais quoi chaton, ta gueule, je suis menteuse, des incohérences dans les réponses, langages populaires, certaines phrases avec beaucoup de fautes d’orographes ou de prononciation, si je tape des fautes elle peut changer de langage soudainement. Parfois la connexion se perd. Ses yeux sont expressifs, son visage bouge et tente de simuler des expressions faciales.\n",
        "\n",
        "https://blog.cfte.education/conversational-ai-examples-how-siri-alexa-google-assistant-have-human-like-conversations/\n",
        "\n",
        "Siri : Sans doute l’un des plus sophistiqué avec Alexa et Google Assistant. Configuré pour ressembler davantage à des humains, générant des réponses plus naturelles et alignées sur des conversations humaines réelles. (Non-supervisé) Design :\n",
        "\n",
        "•\tAutomatic Speech Recognition (ASR)\n",
        "\n",
        "•\tNatural Language Understanding (NLU)\n",
        "\n",
        "•\tMachine Learning to configure a response\n",
        "\n",
        "•\tNatural Language Generation (NLG)\n",
        "\n",
        "•\tText-to-speech Software\n",
        "\n",
        "Test: J’aimerais manger chinois: me donne des restaurants chinois à proximité de chez moi. Je demande une adresse, me donne la durée du trajet avec un itinéraire. Je demande l’anniversaire de mon père, il cherche dans mes contacts pour me donner la date et m’indiqué dans combien de jour. J’aimerais écouter de la nouvelle musique. Ouvre l’application musique sans me fournir de nouveauté. Que se passe-t-il avec Donald Trump. Me donne les dernières nouvelles sur ce personnage. Ou habite ma mère? Siri me demande le nom de ma mère et ensuite me fournit son adresse. Si je demande une opinion si elle aime la Chine, elle regrette et ne peut me répondre. Bref, de loin le meilleur chatbot testé! \n"
      ],
      "metadata": {
        "id": "WScW3whZk7Zp"
      }
    }
  ]
}